{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapport de projet de session - IFT 712\n",
    "### Objectif du projet : tester six méthodes de classification sur une base de données Kaggle.\n",
    "\n",
    "Nous avons choisi la base de données \"[Heart Failure Prediction Dataset][0]\" puisqu'elle permet de faire de la classification sur un jeu de données réel et avec des applications concrètes.\n",
    "Les méthodes de classification que nous allons tester sont les suivantes :\n",
    "* Modèle génératif\n",
    "* K plus proches voisins\n",
    "* Régression logistique\n",
    "* Méthode à noyaux\n",
    "* SVM\n",
    "* Perceptron multicouches\n",
    "\n",
    "Pour cela, nous utiliserons la bibliothèque scikit-learn pour implémenter les algotihmes ainsi que pandas  pour traiter les données\n",
    "\n",
    "Nous utiliserons également [Trello][1] ainsi que discord afin d'organiser le projet\n",
    "Le code est versionné sur [Github][1] en suivant les conventions suivantes :\n",
    "* conventionals [commits][3]\n",
    "* merge requests sur master\n",
    "* une branche par feature (i.e par algorithme de classification)\n",
    "\n",
    "Le code et les commentaires sont rédigés en francais et suivant la convention [pep8][4]. Nous utiliserons la fonctionnalité \"code with me\" de pycharm permettant à plussieurs membres du groupe de coder sur le même projet en même temps\n",
    "\n",
    "[0]: https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction\n",
    "[1]: https://trello.com/b/U21MHLaj/projet-ift712-deadline-11-12-23\n",
    "[2]: https://github.com/MorganChabaudENSSAT/projet_ift712\n",
    "[3]: https://www.conventionalcommits.org/en/v1.0.0/\n",
    "[4]: https://peps.python.org/pep-0008/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T22:10:09.134433300Z",
     "start_time": "2023-12-07T22:10:07.850064400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taill\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    " Imporation des bibliothèques python générales\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "'''\n",
    " Imporation des bibliothèques spécifiques au devoir\n",
    "'''\n",
    "from regression_logistique import RegressionLogistique\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de features dans le dataset : 12\n",
      "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
      "0   40   M           ATA        140          289          0     Normal    172   \n",
      "1   49   F           NAP        160          180          0     Normal    156   \n",
      "2   37   M           ATA        130          283          0         ST     98   \n",
      "3   48   F           ASY        138          214          0     Normal    108   \n",
      "4   54   M           NAP        150          195          0     Normal    122   \n",
      "\n",
      "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
      "0              N      0.0       Up             0  \n",
      "1              N      1.0     Flat             1  \n",
      "2              N      0.0       Up             0  \n",
      "3              Y      1.5     Flat             1  \n",
      "4              N      0.0       Up             0  \n",
      "Age                 int64\n",
      "Sex                object\n",
      "ChestPainType      object\n",
      "RestingBP           int64\n",
      "Cholesterol         int64\n",
      "FastingBS           int64\n",
      "RestingECG         object\n",
      "MaxHR               int64\n",
      "ExerciseAngina     object\n",
      "Oldpeak           float64\n",
      "ST_Slope           object\n",
      "HeartDisease        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Importation des données\n",
    "df = pd.read_csv('heart.csv') # Dataframe contenant les données\n",
    "features_names = df.columns\n",
    "features_nbr = features_names.shape[0]\n",
    "print(f\"nombre de features dans le dataset : {features_nbr}\")\n",
    "# Visualisation des données pour mieux les comprendre\n",
    "print(df.head())\n",
    "print(df.dtypes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T22:10:09.735538600Z",
     "start_time": "2023-12-07T22:10:09.725038400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
      "0     40    1              1        140          289          0           1   \n",
      "1     49    0              2        160          180          0           1   \n",
      "2     37    1              1        130          283          0           2   \n",
      "3     48    0              0        138          214          0           1   \n",
      "4     54    1              2        150          195          0           1   \n",
      "..   ...  ...            ...        ...          ...        ...         ...   \n",
      "913   45    1              3        110          264          0           1   \n",
      "914   68    1              0        144          193          1           1   \n",
      "915   57    1              0        130          131          0           1   \n",
      "916   57    0              1        130          236          0           0   \n",
      "917   38    1              2        138          175          0           1   \n",
      "\n",
      "     MaxHR  ExerciseAngina  Oldpeak  ST_Slope  HeartDisease  \n",
      "0      172               0      0.0         2             0  \n",
      "1      156               0      1.0         1             1  \n",
      "2       98               0      0.0         2             0  \n",
      "3      108               1      1.5         1             1  \n",
      "4      122               0      0.0         2             0  \n",
      "..     ...             ...      ...       ...           ...  \n",
      "913    132               0      1.2         1             1  \n",
      "914    141               0      3.4         1             1  \n",
      "915    115               1      1.2         1             1  \n",
      "916    174               0      0.0         1             1  \n",
      "917    173               0      0.0         2             0  \n",
      "\n",
      "[918 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# A partir de cette visualisation primaire des données, on  remarque que certaines features ne sont pas numériques ce qui empêche de les utiliser telles quelles dans les algorithmes de classification.\n",
    "# => On va donc devoir traiter ces valeurs en les encodant.\n",
    "le = LabelEncoder()\n",
    "\n",
    "data = df.copy(deep = True)\n",
    "\n",
    "data['Sex'] = le.fit_transform(data['Sex'])\n",
    "data['ChestPainType'] = le.fit_transform(data['ChestPainType'])\n",
    "data['RestingECG'] = le.fit_transform(data['RestingECG'])\n",
    "data['ExerciseAngina'] = le.fit_transform(data['ExerciseAngina'])\n",
    "data['ST_Slope'] = le.fit_transform(data['ST_Slope'])\n",
    "\n",
    "# Les données sont mainteant toutes numériques et utilisables par les algorithmes de classification que nous mettrons en place\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T22:10:10.554670200Z",
     "start_time": "2023-12-07T22:10:10.537077400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On observe à présent la distribution de chacune des features car cela peut nous permettre de formuler des hypothèses simplifiant le problème."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T22:10:11.921351100Z",
     "start_time": "2023-12-07T22:10:11.906163700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    " # TODO : Séparation des données en data_test et data_train 20% et 80%"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T22:10:12.598013Z",
     "start_time": "2023-12-07T22:10:12.571503300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1 - Régression logistique ##"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Création du modèle\n",
    "reg_log=RegressionLogistique(data, features_names, features_nbr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T22:10:13.722110800Z",
     "start_time": "2023-12-07T22:10:13.711396700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taill\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "C:\\Users\\taill\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "C:\\Users\\taill\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "C:\\Users\\taill\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "C:\\Users\\taill\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "C:\\Users\\taill\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "C:\\Users\\taill\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "C:\\Users\\taill\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "C:\\Users\\taill\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "C:\\Users\\taill\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    }
   ],
   "source": [
    "# Mise à echelle des données\n",
    "scaled_data = reg_log.scale_data()\n",
    "# Récupération des ensembles d'entraînements et de validation\n",
    "X_train, X_test, y_train, y_test = reg_log.split_data(scaled_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T22:10:14.493342500Z",
     "start_time": "2023-12-07T22:10:14.461762900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taill\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    }
   ],
   "source": [
    "# Entraînement du modèle sur les données d'entraînement\n",
    "reg_log.train(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T22:10:15.733565200Z",
     "start_time": "2023-12-07T22:10:15.710137Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[70 13]\n",
      " [16 85]]\n",
      "accuracy du modèle : 0.842391304347826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taill\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    }
   ],
   "source": [
    "# Evaluation du modèle\n",
    "reg_log.evaluate_model(X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T22:10:18.071769200Z",
     "start_time": "2023-12-07T22:10:18.006756300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "FAux :On cherche à présent à augmenter la capacité du modèle.\n",
    "Pour cela, on utilise implémente une 'cross-validation' et comparons les résultats fournis par le modèle de régression linéaire avec et sans cross-validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_validation : RepeatedStratifiedKFold(n_repeats=3, n_splits=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taill\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    }
   ],
   "source": [
    "reg_log.train(X_train, y_train, cross_val=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T22:10:20.941526700Z",
     "start_time": "2023-12-07T22:10:20.884499900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[70 13]\n",
      " [16 85]]\n",
      "accuracy du modèle : 0.842391304347826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taill\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    }
   ],
   "source": [
    "# Evaluation du modèle avec cross_validation\n",
    "reg_log.evaluate_model(X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T22:12:24.902282800Z",
     "start_time": "2023-12-07T22:12:24.879486100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
