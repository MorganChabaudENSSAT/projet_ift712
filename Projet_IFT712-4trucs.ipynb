{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapport de projet de session - IFT 712\n",
    "### Objectif du projet : tester six méthodes de classification sur une base de données Kaggle.\n",
    "\n",
    "Nous avons choisi la base de données \"[Heart Failure Prediction Dataset][0]\" puisqu'elle permet de faire de la classification sur un jeu de données réel et avec des applications concrètes.\n",
    "Les méthodes de classification que nous allons tester sont les suivantes :\n",
    "* Réseau de neurones\n",
    "* K plus proches voisins\n",
    "* Régression logistique\n",
    "* Modèle Gaussien naïf\n",
    "* SVM\n",
    "* Forêt aléatoire\n",
    "\n",
    "Pour cela, nous utiliserons la bibliothèque scikit-learn pour implémenter les algotihmes ainsi que pandas  pour traiter les données\n",
    "\n",
    "Nous utiliserons également [Trello][1] ainsi que discord afin d'organiser le projet à haut niveau\n",
    "Le code est versionné sur [Github][1] en suivant les conventions suivantes :\n",
    "* conventionals [commits][3]\n",
    "* merge requests sur master\n",
    "* une branche par feature\n",
    "\n",
    "Le code et les commentaires sont rédigés en francais et suivant la convention [pep8][4] au possible. Nous utiliserons la fonctionnalité \"code with me\" de pycharm permettant à plussieurs membres du groupe de coder sur le même projet en même temps\n",
    "\n",
    "[0]: https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction\n",
    "[1]: https://trello.com/b/U21MHLaj/projet-ift712-deadline-11-12-23\n",
    "[2]: https://github.com/MorganChabaudENSSAT/projet_ift712\n",
    "[3]: https://www.conventionalcommits.org/en/v1.0.0/\n",
    "[4]: https://peps.python.org/pep-0008/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-12T04:57:49.956905400Z",
     "start_time": "2023-12-12T04:57:49.401090200Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (svm.py, line 17)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001B[1;36m(most recent call last)\u001B[0m:\n",
      "  File \u001B[0;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3369\u001B[0m in \u001B[0;35mrun_code\u001B[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001B[1;36m  Input \u001B[1;32mIn [18]\u001B[1;36m in \u001B[1;35m<cell line: 19>\u001B[1;36m\u001B[0m\n\u001B[1;33m    from svm import Svm\u001B[0m\n",
      "\u001B[1;36m  File \u001B[1;32m~\\Documents\\UdS\\techniques_apprentissage\\projet_ift712\\svm.py:17\u001B[1;36m\u001B[0m\n\u001B[1;33m    match model:\u001B[0m\n\u001B[1;37m          ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    " Imporation des bibliothèques python générales\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "\n",
    "'''\n",
    " Imporation des bibliothèques spécifiques au devoir\n",
    "'''\n",
    "from regression_logistique import RegressionLogistique\n",
    "from svm import Svm\n",
    "from reseau_neurones import Reseau_neurones\n",
    "import utils\n",
    "\n",
    "'''\n",
    "    Suppression des Future Warnings \n",
    "'''\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=ConvergenceWarning)\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.488566Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importation des données\n",
    "df = pd.read_csv('heart.csv') # Dataframe contenant les données\n",
    "features_names = df.columns\n",
    "features_nbr = features_names.shape[0]\n",
    "print(f\"nombre de features dans le dataset : {features_nbr}\")\n",
    "# Visualisation des données pour mieux les comprendre\n",
    "print(df.head())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.492580800Z"
    }
   },
   "outputs": [],
   "source": [
    "# A partir de cette visualisation primaire des données, on  remarque que certaines features ne sont pas numériques ce qui empêche de les utiliser telles quelles dans les algorithmes de classification.\n",
    "# => On va donc devoir traiter ces valeurs en les encodant.\n",
    "le = LabelEncoder()\n",
    "\n",
    "data = df.copy(deep = True)\n",
    "\n",
    "data['Sex'] = le.fit_transform(data['Sex'])\n",
    "data['ChestPainType'] = le.fit_transform(data['ChestPainType'])\n",
    "data['RestingECG'] = le.fit_transform(data['RestingECG'])\n",
    "data['ExerciseAngina'] = le.fit_transform(data['ExerciseAngina'])\n",
    "data['ST_Slope'] = le.fit_transform(data['ST_Slope'])\n",
    "\n",
    "# Les données sont mainteant toutes numériques et utilisables par les algorithmes de classification que nous mettrons en place\n",
    "print(data)\n",
    "\n",
    "categorical_features = ['Sex','ChestPainType','RestingECG','ExerciseAngina','ST_Slope']\n",
    "numerical_features = [x for x in features_names if x not in categorical_features]\n",
    "numerical_features = numerical_features[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "A présent, on explore les données à l'aide de visualisations afin de mieux comprendre leur nature et détecter les features les plus caractéristiques ainsi que la nature des distributions des données afin, au besoin, de formuler des hypothèses nous permettant de mettre en oeuvre différents modèles.\n",
    "On commence par visualiser la distribution de chaque feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.495656700Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,16))\n",
    "for i in range(features_nbr):\n",
    "    plt.subplot(int(features_nbr/2), 2, i+1)\n",
    "    fig.tight_layout()\n",
    "    cur_feature =features_names[i]\n",
    "    sns.distplot(data[cur_feature], kde_kws={'bw' : 1})\n",
    "    plt.title(\"Distribution de \"+cur_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Régression logistique #"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Création d'un modèle de base avec un pénalité l2 et un facteur de prise en compte de la pénalité de 1 centième\n",
    "reg_log_naif=RegressionLogistique(data, features_names, features_nbr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.498094Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On met à l'echelle les données afin de réduire l'impact des différentes valeurs que peuvent prendre les données sur la précision du modèle.\n",
    "On normalise et standardise toutes les données numériques."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Mise à echelle des données\n",
    "scaled_data = reg_log_naif.scale_data(numerical_features,numerical_features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.501006300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On peut alors récupérer les ensembles d'entrainement et de test et procéder à l'entraînement du modèle."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Récupération des ensembles d'entraînements et de validation\n",
    "X_train, X_test, y_train, y_test = reg_log_naif.split_data(scaled_data)\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "reg_log_naif.train(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.503457900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "on commence par évaluer la capacité d'apprentissage du modèle en appliquant un algorithme de cross validation stratifié."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reg_log_naif.K_fold(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.505774Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Le score de cross-validation du modèle est:  0.848741206960385\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On évalue le modèle sur les données de test."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluation du modèle sur les données de test\n",
    "reg_log_naif.evaluate_model(X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.510052Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On constate que les score de cross-validation et d'accuracy sont a peu près les même : 85%\n",
    "Cela laisse penser que le modèle ne sur apprend pas les données.\n",
    "On vérifie cela rapidmeent en évaluant le modèle sur l'ensemble d'entraînement"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reg_log_naif.evaluate_model(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.512382800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "La remarque précédente es validée : il n'y a pas de sur apprentissage.\n",
    "On va donc cherche maintenant à augmenter la capacité du modèle."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Recherche d'un modèle de plus grande capacité ###\n",
    "On cheche a présent à obtenir un modèle de plus grande qualité. Pour cela, on va comparer plusieurs régressions logistiques initialisées avec des hyperparamètres dfférents afin d'obtenir la combinaison optimal des hyperparamètres.\n",
    "D'après le site de la bibliothèque sklearn, les hyperparamètres sur lesquels il est le plus important d'influer dans le cadre de la régression logistique et que nous étudierons en conséquence sont les suivants:\n",
    "- le 'solver' c'est à dire l'algorithme d'optimisation qui minimise la loss\n",
    "- 'penalty' qui correspond à la norme employée dans le terme de régularisation\n",
    "- 'C' est la constante qui régule l'impact du terme de régularisation (c'est l'inverse de la force de régularisation)\n",
    "\n",
    "Par la suite, on cherche donc a analyser les résultats des différentes combinaisons d'hyperparamètres de sorte à maximiser la capacité du système **tout en** l'empêchant d'overfitter sur les données. Pour cela, on visualisera l'évolution de l'accuracy sur les ensembles d'entraînement et de validation en procédant à une recherche d'hyperparamètres de type 'grid-search' reposant sur la 'cross_validation'.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config_1 = {\n",
    "    'solver' : ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga'],\n",
    "    'penalty' : ['l2'],\n",
    "    'C' : np.logspace(-4,4,40)\n",
    "}\n",
    "\n",
    "config_2 = {\n",
    "    'solver' : ['lbfgs', 'newton-cg', 'sag', 'saga'],\n",
    "    'penalty' : ['none'],\n",
    "    'C' : np.logspace(-4,4,30)\n",
    "}\n",
    "\n",
    "config_3 = {\n",
    "    'solver' : ['liblinear', 'saga'],\n",
    "    'penalty' : ['l1'],\n",
    "    'C' : np.logspace(-4,4,30)\n",
    "}\n",
    "\n",
    "config_4 = {\n",
    "    'solver' : ['saga'],\n",
    "    'penalty' : ['elasticnet'],\n",
    "    'l1_ratio' : np.linspace(0,1,20),\n",
    "    'C' : np.logspace(-4,4,30)\n",
    "}\n",
    "\n",
    "h_parameters_to_tune =[config_1, config_2, config_3, config_4]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.514721100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "post_grid_search_estimator = reg_log_naif.hyper_parameters_search(X_train, y_train, h_parameters_to_tune)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.516742700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Malgré la recherche d'hyperparamètre par grid-search, on trouve un modèle qui présente moins d'accuracy sur les données que le modèle naïf.\n",
    "Cela peut être dû a une exploration trop peu exhaustive des configurations d'hyperparamètres possibles\n",
    "On procède tout de même à l'évaluation de ce modèle."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reg_log_2 = RegressionLogistique(scaled_data, features_names, features_nbr, post_grid_search_estimator)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.519884100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reg_log_2.evaluate_model(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.521886700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reg_log_2.K_fold(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.523886800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Amélioration du modèle : Nombre de données"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On trace les courbes d'entraînement et de validation en fonction du nombre de données."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_size = np.linspace(0.2,1,16)\n",
    "reg_log_2.data_needed_for_max_score(X_train, y_train, train_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.527541300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On constate que le modèle stagne sur l'entraînement. Cependant, la validation augmente bien avec le nombre de données. Cela semble indiquer que les paramètres choisis pour la régression logistique ne sont pas optimaux.\n",
    "Or, la recherche d'hyperparamètres permet de trouver les paramètres optimaux donc on peut supposer que les données ne sont pas assez explicite. il faudrait donc retravailler sur les données avec des outils de préprocessing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Conclusion sur le modèle de régression logistique"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous avons construit un modèle de régression logistique permettant de classifier avec environ 85% de précision les données.\n",
    "Toutefois, un nombre de données accru ainsi qu'un pré processing des données plus poussé (utilisant par exemple une matrice de correlation permettant de distinguer les features les plus importantes) est une piste d'amélioration pour le modèle."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 - K plus proches voisins"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dans cette partie, on classifie les données à l'aide du classifieur par K plus proches voisins.\n",
    "Nous évaluerons la valeur de l'hyperparamètre K à l'aide d'une recherche de type 'grid-search' utilisant une 'stratified-cross-validation'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On commence par initialiser un classifieur dit 'naïf' avec l'hyperparamètre K=5 afin d'avoir une base sur laquelle travailler."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from k_plus_proches_voisins import K_PP_voisins\n",
    "\n",
    "# Instantiation du modèle avec K =5\n",
    "knn_model_naif =  K_PP_voisins(data, features_names, features_nbr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.529542500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On entraîne le modèle sur les données non traitées"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Génération des ensembles d'entrainement et de test\n",
    "X_train, X_test, y_train, y_test = knn_model_naif.split_data(data)\n",
    "# Entraînement du modèle sur les données X_train et y_train\n",
    "knn_model_naif.train(X_train, y_train)\n",
    "# Evaluation du modèle\n",
    "knn_model_naif.evaluate_model(X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Le modèle a une accuracy de 70%, ce qui semble assez faible. Cela est bien sûr causé par l'utilisation du modèle sur des données non transformées."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On normalise puis standardise les données numériques afin de comparer le gain d'accuracy entre les deux modèles."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Normalisation des données numériques\n",
    "scaled_data_knn = knn_model_naif.scale_data(numerical_features,numerical_features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.532543800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On Visualise les données afin de nous assurer que les opérations ont été réalisées avec succès"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(data)\n",
    "print(scaled_data_knn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.534660300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On peut alors entraîner le modèle de classification par K plus proches voisins sur les données transformées"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Instantiation du modèle avec K =5\n",
    "knn_model_naif_2 =  K_PP_voisins(data, features_names, features_nbr)\n",
    "# Génération des ensembles d'entrainement et de test a partir des données transformées\n",
    "X_train, X_test, y_train, y_test = knn_model_naif_2.split_data(scaled_data_knn)\n",
    "# Entraînement du modèle sur les données X_train et y_train\n",
    "knn_model_naif_2.train(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.538168800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On évalue la capacité du modèle à apprendre les données d'entraînement à l'aide de 'stratified-cross-validation'. Les données sur lesquelles est entrainé le modèle sont séparées en un ensemble d'entraînement et de validation permettant d'évaluer la capacité à généraliser du modèle. On évalue le score sur chaque fold puis on en prend la moyenne afin d'obtenir la meilleure évaluation de l'accuracy possible"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn_model_naif_2.K_fold(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.540169400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On évalue à présent le modèle sur les données de test."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluation du modèle sur les données de test\n",
    "knn_model_naif_2.evaluate_model(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.543169600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Le modèle arrive à prédire correctement l'existence ou l'absence de maladie cardiaque dans environ 82% des cas sur les données de tests.\n",
    "On constate une forte augmentation de l'accuracy du modèle par rapport au premier grâce au pré-traitement effectué sur les données."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Amélioration du modèle : recherche des hyperparamètres"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "L'analyse de base du classifieur étant établie, on procède maintenant à une recherche d'hyperparamètres. D'après la documentation de [sklearn][1] les hyperparamètres du modèles sont les suivants :\n",
    "- n_neighbors : le nombre de voisins nécesaires pour la classification du point courant\n",
    "- weights : La métrique utilisée pour prédire l'appartenance d'un point à une classe ou à une autre\n",
    "- algorithm : algorithme utilisé pour le calcul\n",
    "- leaf_size : nombre de points à partir duquel l'algorithme choisi les voisins en force brute\n",
    "- p : puissance dans la distance de Minkowski indiquant la nature de la mesure\n",
    "- metric : la métrique utilisée\n",
    "\n",
    "On conserve la métrique de base (Minkowski) car le choix de la valeur de p permet de choisir la métrique indirectement.\n",
    "Le jeu de données étant inférieur à 1000 points, on peut utiliser l'approche par force brute directement car le temps de calcul devrait rester raisonnable. Ainsi, on fixe leaf_size à 1.\n",
    "L'algorithme utilisé pour le calcul des plus proches voisins est laissé à 'auto'.\n",
    "\n",
    "Il nous reste donc à calculer les valeurs d'hyperparmètres suivants:\n",
    "- n_neighbors\n",
    "- weights\n",
    "- p\n",
    "\n",
    "On utilise une recherche d'hyperparamètres de type grid-search. Pour cela, on instancie un dictionnaire contenant les couples (noms du paramètres : valeurs prises par ce paramètre)\n",
    "\n",
    "[1]: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_neighbors_values = np.linspace(1,20,20).astype(int) # valeurs prises par l'hyperparamètre n_neighbors\n",
    "weights_values = ['uniform', 'distance']    # valeurs prises par l'hyperparamètre weights\n",
    "p_values = np.linspace(1,10,10).astype(int) # valeurs prises par l'hyperparamètre p\n",
    "h_parameters_to_tune ={\n",
    "    'n_neighbors' : n_neighbors_values,\n",
    "    'weights' : weights_values,\n",
    "    'p' : p_values\n",
    "}\n",
    "other_parameters=['leaf-size=1','metric=minkowski']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.545674200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn_post_grid_search_estimator = knn_model_naif.hyper_parameters_search(X_train, y_train, h_parameters_to_tune, other_parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.548038400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On constate une amélioration du score de cross-validation d'environ 2.5%"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On intancie maintenant un nouveau classifieur avec les hyperparamètres que nous venons de trouver puis nous l'évaluons sur les données de test "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# instanciation du classifieur unitilisant les hyperparamètres trouvés\n",
    "knn_2=K_PP_voisins(data, features_names, features_nbr,knn_post_grid_search_estimator)\n",
    "# Evaluation\n",
    "knn_2.evaluate_model(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.549056300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "L'accuracy du modèle s'est améliorée de presque 5% grâce au choix d'hyperparamètres que nous avons fait.\n",
    "\n",
    "Afin d'améliorer davantage le modèle, on étudie les interactions entre le modèle et les données"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Amélioration du modèle : nombre de données"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A présent, on étudie le nombre de données nécessaire dans l'ensemble d'entraînement afin de favoriser l'apprentissage du modèle. Pour cela, on va évaluer la performance du modèle sur plusieurs ensembles d'entraînement dont les tailles sont différentes et afficher les résultats obtenus sous la forme de graphiques.\n",
    "Afin de valider la capacité à généraliser du modèle, nous visualiserons également le score obtenu sur l'ensemble des données de validation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_size = np.linspace(0.2,1,8)\n",
    "knn_2.data_needed_for_max_score(X_train, y_train, train_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.551076800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ce graphique indique que la valeur d'accuracy représentée par les courbes d'apprentissage et de validation semble augmenter avec le nombre de données ce qui indique que le modèle n'est pas au bout de son apprentissage. Ainsi, si nous disposions de plus de données, nous pourrions rendre le modèle encore plus performant."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Conclusion sur le modèle des K plus proches voisins"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Le modèle des K plus proches voisins a permis d'obtenir une accuracy de plus de **86%** sur l'ensemble de test aevc les hyperparamètres suivants : **{'n_neighbors': 17, 'p': 1, 'weights': 'uniform'}** ce qui constitue un gain d'environ 16% par rapport au modèle naïf.\n",
    "Nous avons observé que **le modèle pourrait gagner en accuracy en bénéficiant de plus de données lors de l'entraînement**."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T05:41:43.586364200Z",
     "start_time": "2023-12-08T05:41:43.564874600Z"
    },
    "collapsed": false
   },
   "source": [
    "## 3 - Machine à Vecteurs de Support ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la classification à l'aide de SVM, nous allons vérifier les performances des différents types de noyaux, afin de trouver le meilleur modèle possible.\n",
    "Dépendemment du type de noyau utilisé, nous tenterons d'optimiser les hyper-paramètres de chaque modèle afin de trouver le meilleur modèle pour chaque noyau, puis nous comparerons les résultats.\n",
    "### 3.1 - SVM à noyau linéaire\n",
    "Dans le cas du noyau linéaire, il n'existe pas d'hyperparamètres à optimiser comme indiqué dans la documentation sklearn de la classe Support Vector Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.553185100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Création du modèle avec noyau linéaire\n",
    "linear_svm_instance = Svm(data, features_names, features_nbr, model='linear')\n",
    "# Récupération des ensembles d'entraînements et de validation\n",
    "X_train, X_test, y_train, y_test = linear_svm_instance.split_data(data)\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "linear_svm_instance.train(X_train, y_train)\n",
    "# Evaluation du modèle\n",
    "linear_svm_instance.evaluate_model(X_test,y_test, confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.554185600Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = np.linspace(0.2, 1, 8)\n",
    "linear_svm_instance.plot_learning_curves(X_train, y_train, train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fait que les courbes de score évoluent sensiblement de la même façon à partir d'une taille de 350 indique que l'ajustement est relativement approprié."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - SVM à noyau Radial Basis Function\n",
    "On s'intéresse maintenant à la classification par machines à vecteurs de support avec un noyau RBF. Dans ce cas, les paramètres optimisables sont gamma et C.\n",
    "Le paramètre C équilibre la classification incorrecte des exemples d'entraînement par rapport à la simplicité de la surface de décision.Plus C est grand, plus le modèle risque le sur-apprentissage. Le paramètre gamma définit l'influence qu'a un exemple d'entraînement unique, et donc plus gamma est grand, plus les autres exemples doivent être proches pour être affectés. Observons d'abord le résultat brut de classification sans optimisation des hyper-paramètres du modèle à noyau RBF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.557799400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Création du modèle avec noyau rbf\n",
    "rbf_svm_instance = Svm(data, features_names, features_nbr, model='rbf')\n",
    "# Récupération des ensembles d'entraînements et de validation\n",
    "X_train, X_test, y_train, y_test = rbf_svm_instance.split_data(data)\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "rbf_svm_instance.train(X_train, y_train)\n",
    "# Evaluation du modèle\n",
    "rbf_svm_instance.evaluate_model(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observons les scores d'entraînement et de validation avant optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.559800100Z"
    }
   },
   "outputs": [],
   "source": [
    "rbf_svm_instance.plot_learning_curves(X_train, y_train, train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant tenter d'optimiser les paramères gamma et C à l'aide d'un GridSearch de sorte à obtenir le meilleur modèle possible. Ces paramètres sont cruciaux pour la performance des SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.562121700Z"
    }
   },
   "outputs": [],
   "source": [
    "rbf_svm_best_estimator_post_grid = rbf_svm_instance.hyper_parameters_search(X_train, y_train)\n",
    "best_rbf_svm = Svm(data, features_names, features_nbr, rbf_svm_best_estimator_post_grid)\n",
    "best_rbf_svm.evaluate_model(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.563122400Z"
    }
   },
   "outputs": [],
   "source": [
    "best_rbf_svm.plot_learning_curves(X_train, y_train, train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que la précision du modèle est la même après optimisation des paramètres. Les courbes de score sont également les mêmes. On aurait pu s'abstenir d'optimiser le paramètre C, comme indiqué dans la documentation sklearn. En effet, il est conseillé de ne pas modifier la valeur de C sauf si les données sont très bruitées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - SVM à noyau sigmoïde\n",
    "On s'intéresse maintenant à la classification par machines à vecteurs de support avec un noyau sigmoide. Dans ce cas, le paramètre optimisable est coef0. On observe d'abord le résultat sans optimisation des paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.565453100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Création du modèle avec noyau sigmoid\n",
    "sigmoid_svm_instance = Svm(data, features_names, features_nbr, model='sigmoid')\n",
    "# Récupération des ensembles d'entraînements et de validation\n",
    "X_train, X_test, y_train, y_test = sigmoid_svm_instance.split_data(data)\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "sigmoid_svm_instance.train(X_train, y_train)\n",
    "# Evaluation du modèle\n",
    "sigmoid_svm_instance.evaluate_model(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.567714200Z"
    }
   },
   "outputs": [],
   "source": [
    "sigmoid_svm_instance.plot_learning_curves(X_train, y_train, train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les deux courbes de score baissent drastiquement. Cela peut indiquer que le modèle n'est pas bien spécifié ou encore que les données sont mal prétraitées. Essayons d'optimiser les hyper-paramètres afin d'améliorer le fonctionnement du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.569900400Z"
    }
   },
   "outputs": [],
   "source": [
    "sigmoid_svm_best_estimator_post_grid = sigmoid_svm_instance.hyper_parameters_search(X_train, y_train)\n",
    "best_sigmoid_svm = Svm(data, features_names, features_nbr, sigmoid_svm_best_estimator_post_grid)\n",
    "best_sigmoid_svm.evaluate_model(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.572664800Z"
    }
   },
   "outputs": [],
   "source": [
    "best_sigmoid_svm.plot_learning_curves(X_train, y_train, train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate une nette amélioration du modèle de 8%, ainsi que de bien meilleures courbes de score. En effet, les courbes suivent à peu près la même évolution, indiquant que les ajustements sont plutôt corrects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 - SVM à noyau poly\n",
    "Pour le dernier noyau étudié dans le cadre de ce projet, à savoir le noyau polynomial, celui-ci peut-être optimisé par les hyper-paramètres degree et coef0. Observons les résultats du modèle avant de tenter d'optimiser les paramètres à l'aide d'un GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.574173300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Création du modèle avec noyau poly\n",
    "poly_svm_instance = Svm(data, features_names, features_nbr, model='poly')\n",
    "# Récupération des ensembles d'entraînements et de validation\n",
    "X_train, X_test, y_train, y_test = poly_svm_instance.split_data(data)\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "poly_svm_instance.train(X_train, y_train)\n",
    "# Evaluation du modèle\n",
    "poly_svm_instance.evaluate_model(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.575692400Z"
    }
   },
   "outputs": [],
   "source": [
    "poly_svm_instance.plot_learning_curves(X_train, y_train, train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les courbes de score des modèles ne sont pas très bonnes. En effet, l'effet \"dent-de-scie\" observé sur la courbe du score de validation indique que le modèle sur-apprend. Passons à l'optimisation des hyper-paramètres du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.579300500Z"
    }
   },
   "outputs": [],
   "source": [
    "poly_svm_best_estimator_post_grid = poly_svm_instance.hyper_parameters_search(X_train, y_train)\n",
    "best_poly_svm = Svm(data, features_names, features_nbr, poly_svm_best_estimator_post_grid)\n",
    "best_poly_svm.evaluate_model(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.580304200Z"
    }
   },
   "outputs": [],
   "source": [
    "best_poly_svm.plot_learning_curves(X_train, y_train, train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'amélioration du modèle est faible (1%) après optimisation des hyper-paramètres, et ceci est vérifié par la visualisation des scores qui est sensiblement la même qu'avant optimisation des hyper-paramètres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 - Comparaison des noyaux\n",
    "Après étude des modèles en fonction des noyaux et optimisation des hyper-paramètres, on remarque que les modèles qui ont la meilleure précision sont les modèles à noyaux rbf et polynomial. Pour autant, la classification par noyau polynomial semble plus prometteuse car les scores d'entraînement et de validation stagnent au fur et à mesure que la taille de l'ensemble d'entraînement augmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Classification par réseau de neurones\n",
    "Cette partie est consacrée à l'étude de la classification à l'aide de réseau de neurones. On utilise la classe définie par la bibliothèque sklearn nomée MLPClassifier.\n",
    "Avant de pouvoir utiliser le modèle, nous devons standardiser et normaliser les données. Nous utiliserons les classes Min-Max-Scaler et StandardScaler de la bibliothèque sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.582652200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Création d'une instance du modèle\n",
    "neural_network = Reseau_neurones(data, features_names, features_nbr)\n",
    "features_to_standardise = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR']\n",
    "features_to_normalise = features_names\n",
    "scaled_data = neural_network.scale_data(features_to_normalise=features_to_normalise, features_to_standardise=features_to_standardise)\n",
    "X_train, X_test, y_train, y_test = neural_network.split_data(scaled_data)\n",
    "neural_network.train(X_train, y_train)\n",
    "neural_network.evaluate_model(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.584744900Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = np.linspace(0.2, 1, 8)\n",
    "neural_network.plot_learning_curves(X_train, y_train, train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que le modèle voit son score d'entraînement diminuer drastiquement lorsque la taille de l'ensemble d'entraînement augmente, tandis que la courbe qui retrace le score de validation augmente. Le modèle a donc tendance à sur-apprendre quand la taille de l'ensemble d'entraînement croît. On cherche à optimiser les hyper-paramètres, ce que l'on va réaliser à l'aide d'un GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.587069300Z"
    }
   },
   "outputs": [],
   "source": [
    "neural_network_best_estimator_post_grid = neural_network.hyper_parameters_search(X_train, y_train)\n",
    "best_neural_network = Reseau_neurones(scaled_data, features_names, features_nbr, neural_network_best_estimator_post_grid)\n",
    "best_neural_network.train(X_train,y_train)\n",
    "best_neural_network.evaluate_model(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate une amélioration d'environ 3% de la précision du modèle après optimisation des hyper-paramètres.\n",
    "Observons l'apprentissage du réseau de neurones bien paramétré à l'aide de la méthode partial_fit de la classe MLPClassifier de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T04:57:49.589923500Z"
    }
   },
   "outputs": [],
   "source": [
    "best_neural_network.plot_learning_curves(X_train, y_train, train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semble qu'à partir d'un échantillon de 450 données, le modèle dont les hyper-paramètres sont les meilleurs a tendance a moins sur-apprendre."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
